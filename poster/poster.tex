% Unofficial New York University Poster Template
% a fork of https://github.com/anishathalye/gemini
% also refer to https://github.com/k4rtik/uchicago-poster



\documentclass[final]{beamer}

% ====================
% Packages
% ====================

\usepackage[T1]{fontenc}
 \usepackage[utf8]{luainputenc}
\usepackage{lmodern}
\usepackage[size=custom, width=140,height=70, scale=1]{beamerposter}
\usetheme{gemini}
\usecolortheme{cam}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.14}
\usepackage{anyfontsize}
\usepackage{url}
\usepackage{hyperref}
\usepackage{color}
% \usepackage[colorlinks,linkcolor=red,anchorcolor=blue,citecolor=green]{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[lined,boxed,commentsnumbered]{algorithm2e}
\usepackage{floatrow}


% ====================
% Lengths
% ====================

% If you have N columns, choose \sepwidth and \colwidth such that
% (N+1)*\sepwidth + N*\colwidth = \paperwidth
\newlength{\sepwidth}
\newlength{\colwidth}
\setlength{\sepwidth}{0.025\paperwidth}
\setlength{\colwidth}{0.3\paperwidth}

\newcommand{\separatorcolumn}{\begin{column}{\sepwidth}\end{column}}

% ====================
% Title
% ====================

\title{A Multi-Label Sentiment Classification Approach using ERNIE 3.0 Pre-trained Model}

\author{Xinhui Lin}

\institute[shortinst]{School of Computer Science and Engineering, Northeastern University}

% ====================
% Logo (optional)
% ====================

% use this to include logos on the left and/or right side of the header:
% Left: institution
 \logoleft{\includegraphics[height=8cm]{logos/neu.png}}
% Right: funding agencies and other affilations 
%\logoright{\includegraphics[height=7cm]{logos/NSF.eps}}
% ====================
% Body
% ====================

% \logoright{\includegraphics[height=5cm]{logos/school_logo.jpg}}

\begin{document}



\begin{frame}[t]
\begin{columns}[t]
\separatorcolumn

\begin{column}{\colwidth}

\begin{block}{Introduction \& Motivation}

    Sentiment analysis plays a vital role in natural language processing (NLP) tasks. Over recent years, the landscape of sentiment analysis tasks has evolved from basic multi-class problems, such as positive-negative-neutral classification, to more intricate multi-label problems. These advanced tasks require classifiers to identify and output specific emotions contained within the text. This shift poses challenges for language models.

The predominant approach in the NLP field involves employing pre-training and fine-tuning strategies. This method typically includes constructing a model with numerous parameters, undertaking self-supervised auto-regression training on a large general corpus, and subsequently fine-tuning it on specific datasets tailored to particular tasks.

In this study, the ERNIE 3.0 base model is employed to conduct multi-label sentiment analysis on a given dataset.

  \end{block}
  
  \begin{block}{Dataset Preprocess}

      \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{logos/2024-01-01_21-35.png}
        \caption{train dataset demonstration}
        \label{fig: ERNIE 3.0 framework}
    \end{figure}

  Validate the algorithm's viability and evaluate its performance on the provided dataset. The training dataset comprises 26,000 entries, each presented as [id, text, label]. Thirty percent of the data is randomly assigned for validation, with the remaining 70\% designated as the training set. For each sample (a row in the CSV file), the text field undergoes processing, including trimming leading and trailing whitespaces, eliminating spaces from pre-tokenization, and subsequent input into a tokenizer to generate word vectors. The labels undergo one-hot encoding.

Following this preprocessing, the pre-trained model undergoes fine-tuning on the partitioned training set, and the optimal model is selected through validation. The saved optimal model is then utilized for inference on the testings set, consisting of 6,153 entries in the format [id, text]. The model outputs the one-hot encoded labels corresponding to the text field, subsequently binarized into readable labels based on a specified threshold.


    

  \end{block}

     \begin{block}{Code Availability}

 The data, code, and models utilized in this project have been made available as open source. 
 
 The repository is accessible at \href{https://github.com/hilinxinhui/kdd}{https://github.com/hilinxinhui/kdd}. 
 
 Should you have any inquiries or wish to provide feedback, kindly do so by submitting an issue on the repository.


  \end{block}

\end{column}

\separatorcolumn

\begin{column}{\colwidth}

  

  \begin{block}{Model \& Algorithm}

    \begin{figure}
        \centering
        \includegraphics[width=1\textwidth]{logos/ernie-framework.png}
        \caption{ERNIE 3.0 framework}
        \label{fig: ERNIE 3.0 framework}
    \end{figure}

% Algorithm 1: Fine-tuning Stage
\begin{algorithm}[H]
  \caption{Fine-tuning Stage}
  \label{alg:fine-tuning}
  \begin{algorithmic}[1]
    \REQUIRE Pre-trained model, labeled downstream task training set
    \ENSURE Fine-tuned model
    \STATE Data cleaning: Remove invalid characters, pre-tokenization, generate word vectors for input text, and create one-hot encoding for labels.
    \STATE Split the training set into training and validation sets.
    \STATE Train the pre-trained model with input word vectors. Test the model on the validation set every 50 steps, measuring AUC, F1-Score, Precision, and Recall scores.
    \STATE Save the model with the highest F1-Score on the validation set as the fine-tuned model.
  \end{algorithmic}
\end{algorithm}

% Algorithm 2: Inference Stage
\begin{algorithm}[H]
  \caption{Inference Stage}
  \begin{algorithmic}[1]
    \REQUIRE Fine-tuned model, unlabeled downstream task test set
    \ENSURE Labels for the downstream task test set
    \STATE Preserve all hyperparameters from data processing. Perform word embedding and one-hot encoding on the test set.
    \STATE Use the fine-tuned model from Algorithm 1 to predict labels for the generated word vectors.
    \STATE Apply the sigmoid activation function to the predicted labels and binarize according to a given threshold.
    \STATE Generate original labels corresponding to the binarized results.
    \STATE Save the labels for each sample in the test set.
  
  \end{algorithmic}
\end{algorithm}

   

  \end{block}




\end{column}

\separatorcolumn

\begin{column}{\colwidth}

  \begin{block}{Experiment}

    % % Like this:

    \begin{table}
    \begin{minipage}{0.48\linewidth}
      \centering
      \begin{tabular}{l r r c}
        \toprule
        \textbf{Hyperparameter} & \textbf{Value} \\
    \midrule
    Maximum Tokenizer Sequence Length & 100 \\
    Test Set Batch Size & 16 \\
    Validation Set Batch Size & 16 \\
    Initial Learning Rate & 2e-5 \\
    Learning Rate Decay Rate/Epochs & 0.5 \\
    Optimizer & AdamW \\
    Loss Function & BCEWithLogitsLoss \\
    Fine-tuning Epochs & 4 \\
    Inference Binarization Threshold & 0.38 \\
        \bottomrule
      \end{tabular}
      \caption{table of hyperparameters}
      \end{minipage}
      \begin{minipage}{0.48\linewidth}
      \centering
      \begin{tabular}{l r r c}
        \toprule
        \textbf{Metrics} & \textbf{Score} \\
        \midrule
         AUC & 0.91337 \\
    F1-Score & 0.67598 \\
    Precision & 0.64911 \\
    Recall & 0.70517 \\
        \bottomrule
      \end{tabular}
      \caption{performance on validation set}
      \end{minipage}
    \end{table}

    % \begin{table}
    %   \centering
    %   \begin{tabular}{l r r c}
    %     \toprule
    %     \textbf{Metrics} & \textbf{Score} \\
    %     \midrule
    %      AUC & 0.91337 \\
    % F1-Score & 0.67598 \\
    % Precision & 0.64911 \\
    % Recall & 0.70517 \\
    %     \bottomrule
    %   \end{tabular}
    %   \caption{A table caption.}
    % \end{table}



  \end{block}

    \begin{block}{Future Works}

\begin{enumerate}
    \item \textbf{Optimizing Model Generalization:} Explore alternative models like TextCNN or RNNs on the limited dataset provided to achieve comparable test accuracies, addressing the challenge of model overfitting due to the mismatch between model parameters and dataset size.
    
    \item \textbf{Adapting to Downstream Tasks Efficiently:} Future research can focus on fine-tuning specific layers of the base model to enhance adaptability to specific sentiment classification tasks, avoiding the introduction of unrelated tasks during pre-training.
    
    \item \textbf{Enhancing Training and Inference Efficiency:} Efforts can be directed towards improving efficiency in both model training and inference. Consider using parallel hardware acceleration during training and implementing model quantization for performance optimization during inference.
\end{enumerate}


  \end{block}



  \begin{block}{References}
% List the references with the \textbf{BibTeX} format in the file named \textbf{poster.bib}.
    \nocite{*}
    \footnotesize{\bibliographystyle{plain}\bibliography{poster}}

  \end{block}

\end{column}

\separatorcolumn
\end{columns}
\end{frame}

\end{document}
